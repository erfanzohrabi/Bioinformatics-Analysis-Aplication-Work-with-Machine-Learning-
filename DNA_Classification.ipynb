{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvSjRrUSLQIVKZlARabEZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erfanzohrabi/Bioinformatics-Analysis-Aplication-Work-with-Machine-Learning-/blob/main/DNA_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ELNRohYyBEM",
        "outputId": "334d8392-eade-4d43-b401-1d7c45080ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+    53\n",
            "-    53\n",
            "Name: Class, dtype: int64\n",
            "['t', 'a', 'c', 't', 'a', 'g', 'c', 'a', 'a', 't', 'a', 'c', 'g', 'c', 't', 't', 'g', 'c', 'g', 't', 't', 'c', 'g', 'g', 't', 'g', 'g', 't', 't', 'a', 'a', 'g', 't', 'a', 't', 'g', 't', 'a', 't', 'a', 'a', 't', 'g', 'c', 'g', 'c', 'g', 'g', 'g', 'c', 't', 't', 'g', 't', 'c', 'g', 't', '+']\n",
            "K Nearest Neighbors: 0.8196428571428571 (0.11136044162620619)\n",
            "Gaussian Process: 0.7982142857142857 (0.08146067662826459)\n",
            "Decision Tree: 0.7125 (0.18582585934148133)\n",
            "Random Forest: 0.5089285714285714 (0.13628872787922988)\n",
            "Neural Network: 0.9125 (0.09762812094883318)\n",
            "AdaBoost: 0.7964285714285715 (0.12931333564451195)\n",
            "Naive Bayes: 0.8839285714285714 (0.09355847783878382)\n",
            "SVM Linear: 0.8839285714285714 (0.10898710371190805)\n",
            "SVM RBF: 0.9125 (0.08003905296791061)\n",
            "SVM Sigmoid: 0.9107142857142858 (0.09845749108635873)\n",
            "K Nearest Neighbors\n",
            "Accuracy: 0.7407407407407407\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.56      0.72        16\n",
            "           1       0.61      1.00      0.76        11\n",
            "\n",
            "    accuracy                           0.74        27\n",
            "   macro avg       0.81      0.78      0.74        27\n",
            "weighted avg       0.84      0.74      0.74        27\n",
            "\n",
            "Gaussian Process\n",
            "Accuracy: 0.8148148148148148\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.69      0.81        16\n",
            "           1       0.69      1.00      0.81        11\n",
            "\n",
            "    accuracy                           0.81        27\n",
            "   macro avg       0.84      0.84      0.81        27\n",
            "weighted avg       0.87      0.81      0.81        27\n",
            "\n",
            "Decision Tree\n",
            "Accuracy: 0.9259259259259259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93        16\n",
            "           1       0.85      1.00      0.92        11\n",
            "\n",
            "    accuracy                           0.93        27\n",
            "   macro avg       0.92      0.94      0.93        27\n",
            "weighted avg       0.94      0.93      0.93        27\n",
            "\n",
            "Random Forest\n",
            "Accuracy: 0.7037037037037037\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.62      0.71        16\n",
            "           1       0.60      0.82      0.69        11\n",
            "\n",
            "    accuracy                           0.70        27\n",
            "   macro avg       0.72      0.72      0.70        27\n",
            "weighted avg       0.74      0.70      0.71        27\n",
            "\n",
            "Neural Network\n",
            "Accuracy: 0.9259259259259259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93        16\n",
            "           1       0.85      1.00      0.92        11\n",
            "\n",
            "    accuracy                           0.93        27\n",
            "   macro avg       0.92      0.94      0.93        27\n",
            "weighted avg       0.94      0.93      0.93        27\n",
            "\n",
            "AdaBoost\n",
            "Accuracy: 0.9259259259259259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93        16\n",
            "           1       0.85      1.00      0.92        11\n",
            "\n",
            "    accuracy                           0.93        27\n",
            "   macro avg       0.92      0.94      0.93        27\n",
            "weighted avg       0.94      0.93      0.93        27\n",
            "\n",
            "Naive Bayes\n",
            "Accuracy: 0.9259259259259259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        16\n",
            "           1       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.93        27\n",
            "   macro avg       0.92      0.92      0.92        27\n",
            "weighted avg       0.93      0.93      0.93        27\n",
            "\n",
            "SVM Linear\n",
            "Accuracy: 0.9629629629629629\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        16\n",
            "           1       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.96        27\n",
            "   macro avg       0.96      0.97      0.96        27\n",
            "weighted avg       0.97      0.96      0.96        27\n",
            "\n",
            "SVM RBF\n",
            "Accuracy: 0.8888888888888888\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.81      0.90        16\n",
            "           1       0.79      1.00      0.88        11\n",
            "\n",
            "    accuracy                           0.89        27\n",
            "   macro avg       0.89      0.91      0.89        27\n",
            "weighted avg       0.91      0.89      0.89        27\n",
            "\n",
            "SVM Sigmoid\n",
            "Accuracy: 0.8888888888888888\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.90        16\n",
            "           1       0.83      0.91      0.87        11\n",
            "\n",
            "    accuracy                           0.89        27\n",
            "   macro avg       0.88      0.89      0.89        27\n",
            "weighted avg       0.89      0.89      0.89        27\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
        "\n",
        "# Import necessary libraries\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/promoter-gene-sequences/promoters.data'\n",
        "names = ['Class', 'id', 'Sequence']\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(url, names=names)\n",
        "\n",
        "# Extract the 'Class' column and count the occurrences of each class\n",
        "classes = data.loc[:, 'Class']\n",
        "class_counts = classes.value_counts()\n",
        "print(class_counts)\n",
        "\n",
        "# Generate a list of DNA sequences\n",
        "sequences = data.loc[:, 'Sequence'].tolist()\n",
        "\n",
        "# Create a dictionary to store the dataset\n",
        "dataset = {}\n",
        "for i, seq in enumerate(sequences):\n",
        "    nucleotides = list(seq)\n",
        "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
        "    nucleotides.append(classes[i])\n",
        "    dataset[i] = nucleotides\n",
        "\n",
        "# Print the first entry in the dataset dictionary\n",
        "print(dataset[0])\n",
        "\n",
        "# Create a DataFrame from the dataset dictionary\n",
        "df = pd.DataFrame(dataset).T\n",
        "df.rename(columns={57: 'Class'}, inplace=True)\n",
        "\n",
        "# Generate value counts for each column in the DataFrame\n",
        "series = []\n",
        "for name in df.columns:\n",
        "    series.append(df[name].value_counts())\n",
        "\n",
        "# Create a DataFrame to store the value counts\n",
        "info = pd.DataFrame(series)\n",
        "details = info.T\n",
        "\n",
        "# Convert categorical variables into numerical representation\n",
        "numerical_df = pd.get_dummies(df)\n",
        "df = numerical_df.drop(columns=['Class_-'])\n",
        "df.rename(columns={'Class_+': 'Class'}, inplace=True)\n",
        "\n",
        "# Create X and y dataset for training\n",
        "X = df.drop(['Class'], axis=1).to_numpy()\n",
        "y = df['Class'].to_numpy()\n",
        "\n",
        "# Split the data into training and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)\n",
        "\n",
        "# Define scoring method\n",
        "scoring = 'accuracy'\n",
        "\n",
        "# Define models to train\n",
        "names = ['K Nearest Neighbors', 'Gaussian Process', 'Decision Tree', 'Random Forest',\n",
        "         'Neural Network', 'AdaBoost', 'Naive Bayes', 'SVM Linear', 'SVM RBF', 'SVM Sigmoid']\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(n_neighbors=3),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=500),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    SVC(kernel='linear'),\n",
        "    SVC(kernel='rbf'),\n",
        "    SVC(kernel='sigmoid')\n",
        "]\n",
        "\n",
        "# Evaluate each model in turn\n",
        "results = []\n",
        "for name, model in zip(names, classifiers):\n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    msg = '{0}: {1} ({2})'.format(name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Test the algorithm on the validation dataset\n",
        "for name, model in zip(names, classifiers):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(name)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "    print(classification_report(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a86YtlPBygX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BOzqUkFhySGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}